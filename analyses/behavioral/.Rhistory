freq_frame$SSID[i]=ss_list[i]
freq_frame$task[i]="recent"
freq_frame$pearson_R[i]=corr_freq[1]
corr_fam=corr.test(as.numeric(data_fam$Response),data_fam$norm_fam,method="pearson")
fam_frame$SSID[i]=ss_list[i]
fam_frame$task[i]="lifetime"
fam_frame$pearson_R[i]=corr_fam[1]
}
fam_frame$pearson_R=as.numeric(fam_frame$pearson_R)
freq_frame$pearson_R=as.numeric(freq_frame$pearson_R)
bsize=0.1
library(ggplot2)
#generate ggplots, using ERP data as background
freq.plot=ggplot(data=background_ERP,aes(x=freq)) +
geom_histogram(fill='grey',binwidth = bsize)+
geom_histogram(data=freq_frame,aes(x=pearson_R),binwidth = bsize)+labs(y="participant count", x="frequency correlation")+theme(axis.text=element_text(size=(15)),axis.title=element_text(size=(15)))
fam.plot=ggplot(data=background_ERP,aes(x=fam)) +
geom_histogram(fill='grey',binwidth = bsize)+
geom_histogram(data=fam_frame,aes(x=pearson_R),binwidth=bsize)+labs(y="participant count", x="familiarity correlation")+theme(axis.text=element_text(size=(15)),axis.title=element_text(size=(15)))
#generate barplots as in Devin's paper
View(famavg)
View(freqavg)
freq.bar=ggplot(freqavg,aes(x=obj_freq,y=mean_resp))+geom_col()
freq.bar
install.packages("dplyr")
library(dplyr)
#use piping to chain functions
freq.sum=freqavg %>%
group_by(obj_freq) %>%
summarise(sub_mean=mean(mean_resp),sub_sd=sd(mean_resp),sub_se=sd(mean_resp)/sqrt(n()))
View(freq.sum)
freq.bar=ggplot(freq.sum,aes(x=obj_freq,y=sub_mean))+geom_col()+geom_errorbar(aes(ymin=sub_mean-sub_se,ymax=sub_mean+sub_se),width=0.2)
freq.bar
fam.sum=famavg %>%
group_by(obj_fam) %>%
summarise(sub_mean=mean(mean_resp),sub_sd=sd(mean_resp),sub_se=sd(mean_resp)/sqrt(n()))
fam.bar=ggplot(fam.sum,aes(x=obj_fam,y=sub_mean))+geom_col()+geom_errorbar(aes(ymin=sub_mean-sub_se,ymax=sub_mean+sub_se),width=0.2)
fam.sum=famavg %>%
group_by(norm_fam) %>%
summarise(sub_mean=mean(mean_resp),sub_sd=sd(mean_resp),sub_se=sd(mean_resp)/sqrt(n()))
fam.bar=ggplot(fam.sum,aes(x=obj_fam,y=sub_mean))+geom_col()+geom_errorbar(aes(ymin=sub_mean-sub_se,ymax=sub_mean+sub_se),width=0.2)
fam.bar
fam.sum=famavg %>%
group_by(norm_fam) %>%
summarise(sub_mean=mean(mean_resp),sub_sd=sd(mean_resp),sub_se=sd(mean_resp)/sqrt(n()))
fam.bar=ggplot(fam.sum,aes(x=norm_fam,y=sub_mean))+geom_col()+geom_errorbar(aes(ymin=sub_mean-sub_se,ymax=sub_mean+sub_se),width=0.2)
fam.bar
freq.bar
library(rio)
library(plyr)
SSID=c('001','002','003','004','005','006','007','008','010','011','012','013')
i=1
temp_data=import(paste0("C:\\Users\\haozi\\Desktop\\PhD\\fMRI_PrC-PPC_data\\behavioral\\sub-",SSID[i],'\\',SSID[i],'_startphase-study_startrun-1_starttrial-1_data.xlsx'))
animacy_data=temp_data[temp_data$task=='animacy',]
ps_data=temp_data[temp_data$task=='post_scan',]
words.9=unique(animacy_data$Stimuli[animacy_data$objective_freq==91])
words.9=words.9[!is.na(words.9)]
words.1=unique(animacy_data$Stimuli[animacy_data$objective_freq==11])
words.1=words.1[!is.na(words.1)]
norm.9=animacy_data$norm_fam[animacy_data$objective_freq==91&animacy_data$Stimuli %in% words.9]
norm.1=animacy_data$norm_fam[animacy_data$objective_freq==11&animacy_data$Stimuli %in% words.1]
post.9=ps_data$Response[ps_data$Stimuli %in% words.9]
post.1=ps_data$Response[ps_data$Stimuli %in% words.1]
(post.9-1)/8
post.9-1
? rep
post.9-c(rep(1,length(post.9)))
class(post.9)
norm.9-1
as.numeric(post.9)
post.9=as.numeric(ps_data$Response[ps_data$Stimuli %in% words.9])
post.1=as.numeric(ps_data$Response[ps_data$Stimuli %in% words.1])
norm.9.st=(norm.9-1)/8
norm.1.st=(norm.1-1)/8
post.9.st=(post.9-1)/5
post.1.st=(post.1-1)/5
#calculate the avg. post-pre differences
post_pre.9=post.9.st-norm.9.st
post_pre.1=post.1.st-norm.1.st
pp.9.mean=mean(post_pre.9)
pp.1.mean=mean(post_pre.1)
data=data.frame()
colnames(data)=c('pp_9','pp_1')
#for each subject, calculate the average difference of normative lifetime ratings between the two most extreme bins, and the average difference in post-scan ratings
data=data.frame(matrix(1,2))
View(data)
#for each subject, calculate the average difference of normative lifetime ratings between the two most extreme bins, and the average difference in post-scan ratings
data=data.frame(matrix(2,1))
#for each subject, calculate the average difference of normative lifetime ratings between the two most extreme bins, and the average difference in post-scan ratings
data=data.frame(pp_9=as.numeric(),pp_1=as.numeric())
View(data)
#for each subject, calculate the average difference of normative lifetime ratings between the two most extreme bins, and the average difference in post-scan ratings
data=data.frame(pp_9=as.numeric(),pp_1=as.numeric(),SSID=as.character())
#check if repetition in the study phase boosted lifetime familiarity ratings post-scan
#use normtive lifetime ratings as baseline, compare post-pre (subject rating - normative rating) lifetime rating difference for words presented 9 times with those presented 1 times.
#This is more sensitive than just correlating lifetime rating with presentation frequency since it takes the baseline difference of lifetime ratings between the bins into consideration. Also, it is likely that the repetition only had a small effect on lifetime ratings, which may not give a significant correlation.
library(rio)
library(plyr)
SSID=c('001','002','003','004','005','006','007','008','010','011','012','013')
#for each subject, calculate the average difference of normative lifetime ratings between the two most extreme bins, and the average difference in post-scan ratings
data=data.frame(pp_9=as.numeric(),pp_1=as.numeric(),SSID=as.character())
for (i in c(1:length(SSID))){
temp_data=import(paste0("C:\\Users\\haozi\\Desktop\\PhD\\fMRI_PrC-PPC_data\\behavioral\\sub-",SSID[i],'\\',SSID[i],'_startphase-study_startrun-1_starttrial-1_data.xlsx'))
animacy_data=temp_data[temp_data$task=='animacy',]
ps_data=temp_data[temp_data$task=='post_scan',]
words.9=unique(animacy_data$Stimuli[animacy_data$objective_freq==91])
words.9=words.9[!is.na(words.9)]
words.1=unique(animacy_data$Stimuli[animacy_data$objective_freq==11])
words.1=words.1[!is.na(words.1)]
norm.9=animacy_data$norm_fam[animacy_data$objective_freq==91&animacy_data$Stimuli %in% words.9]
norm.1=animacy_data$norm_fam[animacy_data$objective_freq==11&animacy_data$Stimuli %in% words.1]
post.9=as.numeric(ps_data$Response[ps_data$Stimuli %in% words.9])
post.1=as.numeric(ps_data$Response[ps_data$Stimuli %in% words.1])
#range normalization since norm and post-scan ratings are on different scales
norm.9.st=(norm.9-1)/8
norm.1.st=(norm.1-1)/8
post.9.st=(post.9-1)/5
post.1.st=(post.1-1)/5
#calculate the avg. post-pre differences
post_pre.9=post.9.st-norm.9.st
post_pre.1=post.1.st-norm.1.st
pp.9.mean=mean(post_pre.9)
pp.1.mean=mean(post_pre.1)
data=rbind(data,data.frame(pp.9.mean,pp.1.mean,SSID[i]))
}
#t-test compare pre-post lifetime rating differences
View(data)
i=10
temp_data=import(paste0("C:\\Users\\haozi\\Desktop\\PhD\\fMRI_PrC-PPC_data\\behavioral\\sub-",SSID[i],'\\',SSID[i],'_startphase-study_startrun-1_starttrial-1_data.xlsx'))
View(temp_data)
animacy_data=temp_data[temp_data$task=='animacy',]
ps_data=temp_data[temp_data$task=='post_scan',]
words.9=unique(animacy_data$Stimuli[animacy_data$objective_freq==91])
words.9=words.9[!is.na(words.9)]
words.1=unique(animacy_data$Stimuli[animacy_data$objective_freq==11])
words.1=words.1[!is.na(words.1)]
norm.9=animacy_data$norm_fam[animacy_data$objective_freq==91&animacy_data$Stimuli %in% words.9]
norm.1=animacy_data$norm_fam[animacy_data$objective_freq==11&animacy_data$Stimuli %in% words.1]
post.9=as.numeric(ps_data$Response[ps_data$Stimuli %in% words.9])
post.1=as.numeric(ps_data$Response[ps_data$Stimuli %in% words.1])
#range normalization since norm and post-scan ratings are on different scales
norm.9.st=(norm.9-1)/8
norm.1.st=(norm.1-1)/8
post.9.st=(post.9-1)/5
post.1.st=(post.1-1)/5
#calculate the avg. post-pre differences
post_pre.9=post.9.st-norm.9.st
post_pre.1=post.1.st-norm.1.st
pp.9.mean=mean(post_pre.9)
pp.1.mean=mean(post_pre.1)
norm.9
norm.1
post.1
post.9
post_pre.9
post_pre.1
#check if repetition in the study phase boosted lifetime familiarity ratings post-scan
#use normtive lifetime ratings as baseline, compare post-pre (subject rating - normative rating) lifetime rating difference for words presented 9 times with those presented 1 times.
#This is more sensitive than just correlating lifetime rating with presentation frequency since it takes the baseline difference of lifetime ratings between the bins into consideration. Also, it is likely that the repetition only had a small effect on lifetime ratings, which may not give a significant correlation.
library(rio)
library(plyr)
SSID=c('001','002','003','004','005','006','007','008','010','011','012','013')
#for each subject, calculate the average difference of normative lifetime ratings between the two most extreme bins, and the average difference in post-scan ratings
data=data.frame(pp_9=as.numeric(),pp_1=as.numeric(),SSID=as.character())
for (i in c(1:length(SSID))){
temp_data=import(paste0("C:\\Users\\haozi\\Desktop\\PhD\\fMRI_PrC-PPC_data\\behavioral\\sub-",SSID[i],'\\',SSID[i],'_startphase-study_startrun-1_starttrial-1_data.xlsx'))
animacy_data=temp_data[temp_data$task=='animacy',]
ps_data=temp_data[temp_data$task=='post_scan',]
words.9=unique(animacy_data$Stimuli[animacy_data$objective_freq==91])
words.9=words.9[!is.na(words.9)]
words.1=unique(animacy_data$Stimuli[animacy_data$objective_freq==11])
words.1=words.1[!is.na(words.1)]
norm.9=animacy_data$norm_fam[animacy_data$objective_freq==91&animacy_data$Stimuli %in% words.9]
norm.1=animacy_data$norm_fam[animacy_data$objective_freq==11&animacy_data$Stimuli %in% words.1]
post.9=as.numeric(ps_data$Response[ps_data$Stimuli %in% words.9])
post.1=as.numeric(ps_data$Response[ps_data$Stimuli %in% words.1])
#range normalization since norm and post-scan ratings are on different scales
norm.9.st=(norm.9-1)/8
norm.1.st=(norm.1-1)/8
post.9.st=(post.9-1)/5
post.1.st=(post.1-1)/5
#calculate the avg. post-pre differences
post_pre.9=post.9.st-norm.9.st
post_pre.1=post.1.st-norm.1.st
pp.9.mean=mean(post_pre.9,na.rm=TRUE)
pp.1.mean=mean(post_pre.1,na.rm=TRUE)
data=rbind(data,data.frame(pp.9.mean,pp.1.mean,SSID[i]))
}
#t-test compare pre-post lifetime rating differences
View(data)
#t-test compare pre-post lifetime rating differences
pp.9_1.t=t.test(data$pp.9.mean,data$pp.1.mean,paired = TRUE)
pp.9_1.t
#correlate frequency judgement with actual presentation frequency, and lifetime fam judgement with normative data.
#using results from my ERP study as background to judge the data quality of the fMRI study.
datapath="C:\\Users\\haozi\\Desktop\\PhD\\fMRI_PrC-PPC_data\\"
library(psych)
library(readxl)
background_ERP=read_excel(paste(datapath,"resource from ERP study\\only_Pearson_R.xlsx",sep=""), sheet = "transposed")
ss_list=c('001','002','003','004','005','006','007','008','010','011','012','013','014','016','017','018','019','020','021','022','024','095','026','027','028')
#create empty dataframes to store the correlation values
freq_frame=data.frame(matrix(ncol = 3, nrow = length(ss_list)))
x <- c("pearson_R","SSID","task")
colnames(freq_frame) <- x
fam_frame=freq_frame
#creat empty dataframes to store the mean resp for each level of freq and fam for each ss
freqavg=data.frame(matrix(ncol=3,nrow=length(ss_list)*5))
x=c("mean_resp","SSID","obj_freq")
colnames(freqavg)=x
famavg=data.frame(matrix(ncol=3,nrow=length(ss_list)*5))
x=c("mean_resp","SSID","norm_fam")
colnames(famavg)=x
library(gtools)
#load data, calculate correlation and mean resp for each level of freq and fam in a for-loop
for (i in c(1:length(ss_list))){
data_dir=paste(datapath,"behavioral\\sub-",ss_list[i],sep="")
data_file=list.files(data_dir,pattern=paste("^",ss_list[i],"_startphase*",sep=""))
data=read_excel(paste(data_dir,"\\",data_file,sep=""))
#remove rows with all NAs but two columns
data=data[rowSums(is.na(data)) != ncol(data)-2, ]
#extract testphase data
data_freq=data[data$task=="recent",]
data_fam=data[data$task=="lifetime",]
#cut the normative fam ratings into 5 levels
norm_fam_qt=quantcut(data_fam$norm_fam,q=5,labels=FALSE)
data_fam$norm_fam_qt=norm_fam_qt
#average
freqavg$SSID[(5*(i-1)+1):(5*i)]=ss_list[i]
freqavg$obj_freq[(5*(i-1)+1):(5*i)]=seq(1,9,2)
#each level of obj_freq
freqavg$mean_resp[5*(i-1)+1]=mean(as.numeric(data_freq$Response[data_freq$objective_freq==1]),na.rm=TRUE)
freqavg$mean_resp[5*(i-1)+2]=mean(as.numeric(data_freq$Response[data_freq$objective_freq==3]),na.rm=TRUE)
freqavg$mean_resp[5*(i-1)+3]=mean(as.numeric(data_freq$Response[data_freq$objective_freq==5]),na.rm=TRUE)
freqavg$mean_resp[5*(i-1)+4]=mean(as.numeric(data_freq$Response[data_freq$objective_freq==7]),na.rm=TRUE)
freqavg$mean_resp[5*(i-1)+5]=mean(as.numeric(data_freq$Response[data_freq$objective_freq==9]),na.rm=TRUE)
famavg$SSID[(5*(i-1)+1):(5*i)]=ss_list[i]
famavg$norm_fam[(5*(i-1)+1):(5*i)]=c(1:5)
#each level of obj_freq
famavg$mean_resp[5*(i-1)+1]=mean(as.numeric(data_fam$Response[data_fam$norm_fam_qt==1]),na.rm=TRUE)
famavg$mean_resp[5*(i-1)+2]=mean(as.numeric(data_fam$Response[data_fam$norm_fam_qt==2]),na.rm=TRUE)
famavg$mean_resp[5*(i-1)+3]=mean(as.numeric(data_fam$Response[data_fam$norm_fam_qt==3]),na.rm=TRUE)
famavg$mean_resp[5*(i-1)+4]=mean(as.numeric(data_fam$Response[data_fam$norm_fam_qt==4]),na.rm=TRUE)
famavg$mean_resp[5*(i-1)+5]=mean(as.numeric(data_fam$Response[data_fam$norm_fam_qt==5]),na.rm=TRUE)
#correlation
corr_freq=corr.test(as.numeric(data_freq$Response),data_freq$objective_freq,method="pearson")
freq_frame$SSID[i]=ss_list[i]
freq_frame$task[i]="recent"
freq_frame$pearson_R[i]=corr_freq[1]
corr_fam=corr.test(as.numeric(data_fam$Response),data_fam$norm_fam,method="pearson")
fam_frame$SSID[i]=ss_list[i]
fam_frame$task[i]="lifetime"
fam_frame$pearson_R[i]=corr_fam[1]
}
fam_frame$pearson_R=as.numeric(fam_frame$pearson_R)
freq_frame$pearson_R=as.numeric(freq_frame$pearson_R)
bsize=0.1
View(fam_frame)
View(freq_frame)
View(data_fam)
View(data_fam)
View(famavg)
View(data_fam)
library(ggplot2)
#generate ggplots, using ERP data as background
freq.plot=ggplot(data=background_ERP,aes(x=freq)) +
geom_histogram(fill='grey',binwidth = bsize)+
geom_histogram(data=freq_frame,aes(x=pearson_R),binwidth = bsize)+labs(y="participant count", x="frequency correlation")+theme(axis.text=element_text(size=(30)),axis.title=element_text(size=(30)))
fam.plot=ggplot(data=background_ERP,aes(x=fam)) +
geom_histogram(fill='grey',binwidth = bsize)+
geom_histogram(data=fam_frame,aes(x=pearson_R),binwidth=bsize)+labs(y="participant count", x="familiarity correlation")+theme(axis.text=element_text(size=(30)),axis.title=element_text(size=(30)))
freq.plot
fam.plot
freq.plot
fam.plot
ss_list=c('001','002','003','004','005','006','007','008','011','013','014','016','020','021','022','095','026')
#create empty dataframes to store the correlation values
freq_frame=data.frame(matrix(ncol = 3, nrow = length(ss_list)))
x <- c("pearson_R","SSID","task")
colnames(freq_frame) <- x
fam_frame=freq_frame
#creat empty dataframes to store the mean resp for each level of freq and fam for each ss
freqavg=data.frame(matrix(ncol=3,nrow=length(ss_list)*5))
x=c("mean_resp","SSID","obj_freq")
colnames(freqavg)=x
famavg=data.frame(matrix(ncol=3,nrow=length(ss_list)*5))
x=c("mean_resp","SSID","norm_fam")
colnames(famavg)=x
library(gtools)
#load data, calculate correlation and mean resp for each level of freq and fam in a for-loop
for (i in c(1:length(ss_list))){
data_dir=paste(datapath,"behavioral\\sub-",ss_list[i],sep="")
data_file=list.files(data_dir,pattern=paste("^",ss_list[i],"_startphase*",sep=""))
data=read_excel(paste(data_dir,"\\",data_file,sep=""))
#remove rows with all NAs but two columns
data=data[rowSums(is.na(data)) != ncol(data)-2, ]
#extract testphase data
data_freq=data[data$task=="recent",]
data_fam=data[data$task=="lifetime",]
#cut the normative fam ratings into 5 levels
norm_fam_qt=quantcut(data_fam$norm_fam,q=5,labels=FALSE)
data_fam$norm_fam_qt=norm_fam_qt
#average
freqavg$SSID[(5*(i-1)+1):(5*i)]=ss_list[i]
freqavg$obj_freq[(5*(i-1)+1):(5*i)]=seq(1,9,2)
#each level of obj_freq
freqavg$mean_resp[5*(i-1)+1]=mean(as.numeric(data_freq$Response[data_freq$objective_freq==1]),na.rm=TRUE)
freqavg$mean_resp[5*(i-1)+2]=mean(as.numeric(data_freq$Response[data_freq$objective_freq==3]),na.rm=TRUE)
freqavg$mean_resp[5*(i-1)+3]=mean(as.numeric(data_freq$Response[data_freq$objective_freq==5]),na.rm=TRUE)
freqavg$mean_resp[5*(i-1)+4]=mean(as.numeric(data_freq$Response[data_freq$objective_freq==7]),na.rm=TRUE)
freqavg$mean_resp[5*(i-1)+5]=mean(as.numeric(data_freq$Response[data_freq$objective_freq==9]),na.rm=TRUE)
famavg$SSID[(5*(i-1)+1):(5*i)]=ss_list[i]
famavg$norm_fam[(5*(i-1)+1):(5*i)]=c(1:5)
#each level of obj_freq
famavg$mean_resp[5*(i-1)+1]=mean(as.numeric(data_fam$Response[data_fam$norm_fam_qt==1]),na.rm=TRUE)
famavg$mean_resp[5*(i-1)+2]=mean(as.numeric(data_fam$Response[data_fam$norm_fam_qt==2]),na.rm=TRUE)
famavg$mean_resp[5*(i-1)+3]=mean(as.numeric(data_fam$Response[data_fam$norm_fam_qt==3]),na.rm=TRUE)
famavg$mean_resp[5*(i-1)+4]=mean(as.numeric(data_fam$Response[data_fam$norm_fam_qt==4]),na.rm=TRUE)
famavg$mean_resp[5*(i-1)+5]=mean(as.numeric(data_fam$Response[data_fam$norm_fam_qt==5]),na.rm=TRUE)
#correlation
corr_freq=corr.test(as.numeric(data_freq$Response),data_freq$objective_freq,method="pearson")
freq_frame$SSID[i]=ss_list[i]
freq_frame$task[i]="recent"
freq_frame$pearson_R[i]=corr_freq[1]
corr_fam=corr.test(as.numeric(data_fam$Response),data_fam$norm_fam,method="pearson")
fam_frame$SSID[i]=ss_list[i]
fam_frame$task[i]="lifetime"
fam_frame$pearson_R[i]=corr_fam[1]
}
fam_frame$pearson_R=as.numeric(fam_frame$pearson_R)
freq_frame$pearson_R=as.numeric(freq_frame$pearson_R)
bsize=0.1
library(ggplot2)
#generate ggplots, using ERP data as background
freq.plot=ggplot(data=background_ERP,aes(x=freq)) +
geom_histogram(fill='grey',binwidth = bsize)+
geom_histogram(data=freq_frame,aes(x=pearson_R),binwidth = bsize)+labs(y="participant count", x="frequency correlation")+theme(axis.text=element_text(size=(30)),axis.title=element_text(size=(30)))
fam.plot=ggplot(data=background_ERP,aes(x=fam)) +
geom_histogram(fill='grey',binwidth = bsize)+
geom_histogram(data=fam_frame,aes(x=pearson_R),binwidth=bsize)+labs(y="participant count", x="familiarity correlation")+theme(axis.text=element_text(size=(30)),axis.title=element_text(size=(30)))
freq.plot
fam.plot
View(data_freq)
View(data)
View(famavg)
View(freqavg)
#correlate frequency judgement with actual presentation frequency, and lifetime fam judgement with normative data.
#using results from my ERP study as background to judge the data quality of the fMRI study.
datapath="C:\\Users\\haozi\\Desktop\\PhD\\fMRI_PrC-PPC_data\\"
library(psych)
library(readxl)
background_ERP=read_excel(paste(datapath,"resource from ERP study\\only_Pearson_R.xlsx",sep=""), sheet = "transposed")
ss_list=c('001','002','003','004','005','006','007','008','010','011','012','013','014','015','016','017','018','019','020','021','022','023','024','095','026','027','028','029','030','031','032')
#ss_list=c('001','002','003','004','005','006','007','008','011','013','014','016','020','021','022','095','026')
#create empty dataframes to store the correlation values
freq_frame=data.frame(matrix(ncol = 3, nrow = length(ss_list)))
x <- c("pearson_R","SSID","task")
colnames(freq_frame) <- x
fam_frame=freq_frame
postscan_frame=freq_frame
#creat empty dataframes to store the mean resp for each level of freq and fam for each ss
freqavg=data.frame(matrix(ncol=3,nrow=length(ss_list)*5))
x=c("mean_resp","SSID","obj_freq")
colnames(freqavg)=x
famavg=data.frame(matrix(ncol=3,nrow=length(ss_list)*5))
x=c("mean_resp","SSID","norm_fam")
colnames(famavg)=x
postscanavg=data.frame(matrix(ncol=3,nrow=length(ss_list)*5))
x=c("mean_resp","SSID","norm_fam")
colnames(postscanavg)=x
#create empty dataframes to store the mean RT for each judgement
freqRTavg=data.frame(matrix(ncol=3,nrow=length(ss_list)*5))
x=c("mean_RT","SSID","resp")
colnames(freqRTavg)=x
famRTavg=data.frame(matrix(ncol=3,nrow=length(ss_list)*5))
x=c("mean_RT","SSID","resp")
colnames(famRTavg)=x
library(gtools)
#load data, calculate correlation and mean resp for each level of freq and fam in a for-loop
for (i in c(1:length(ss_list))){
data_dir=paste(datapath,"behavioral\\sub-",ss_list[i],sep="")
data_file=list.files(data_dir,pattern=paste("^",ss_list[i],"_startphase*",sep=""))
data=read_excel(paste(data_dir,"\\",data_file,sep=""))
#remove rows with all NAs but two columns
data=data[rowSums(is.na(data)) != ncol(data)-2, ]
#extract testphase data
data_freq=data[data$task=="recent",]
data_fam=data[data$task=="lifetime",]
data_postscan=data[data$task=="post_scan",]
#calculate normfam for frequency items to be compared with post_scan response
data_freq.match=data_freq[match(data_postscan$Stimuli,data_freq$Stimuli),]#match item order
data_postscan$norm_fam=data_freq.match$norm_fam
norm_fam_freq_qt=quantcut(data_postscan$norm_fam,q=5,labels=FALSE)
data_postscan$norm_fam_qt=norm_fam_freq_qt
#cut the normative fam ratings into 5 levels
norm_fam_qt=quantcut(data_fam$norm_fam,q=5,labels=FALSE)
data_fam$norm_fam_qt=norm_fam_qt
#average
freqavg$SSID[(5*(i-1)+1):(5*i)]=ss_list[i]
freqavg$obj_freq[(5*(i-1)+1):(5*i)]=seq(1,9,2)
#each level of obj_freq
freqavg$mean_resp[5*(i-1)+1]=mean(as.numeric(data_freq$Response[data_freq$objective_freq==1]),na.rm=TRUE)
freqavg$mean_resp[5*(i-1)+2]=mean(as.numeric(data_freq$Response[data_freq$objective_freq==3]),na.rm=TRUE)
freqavg$mean_resp[5*(i-1)+3]=mean(as.numeric(data_freq$Response[data_freq$objective_freq==5]),na.rm=TRUE)
freqavg$mean_resp[5*(i-1)+4]=mean(as.numeric(data_freq$Response[data_freq$objective_freq==7]),na.rm=TRUE)
freqavg$mean_resp[5*(i-1)+5]=mean(as.numeric(data_freq$Response[data_freq$objective_freq==9]),na.rm=TRUE)
famavg$SSID[(5*(i-1)+1):(5*i)]=ss_list[i]
famavg$norm_fam[(5*(i-1)+1):(5*i)]=c(1:5)
#each level of obj_freq
famavg$mean_resp[5*(i-1)+1]=mean(as.numeric(data_fam$Response[data_fam$norm_fam_qt==1]),na.rm=TRUE)
famavg$mean_resp[5*(i-1)+2]=mean(as.numeric(data_fam$Response[data_fam$norm_fam_qt==2]),na.rm=TRUE)
famavg$mean_resp[5*(i-1)+3]=mean(as.numeric(data_fam$Response[data_fam$norm_fam_qt==3]),na.rm=TRUE)
famavg$mean_resp[5*(i-1)+4]=mean(as.numeric(data_fam$Response[data_fam$norm_fam_qt==4]),na.rm=TRUE)
famavg$mean_resp[5*(i-1)+5]=mean(as.numeric(data_fam$Response[data_fam$norm_fam_qt==5]),na.rm=TRUE)
postscanavg$SSID[(5*(i-1)+1):(5*i)]=ss_list[i]
postscanavg$norm_fam[(5*(i-1)+1):(5*i)]=c(1:5)
#each level of obj_freq
postscanavg$mean_resp[5*(i-1)+1]=mean(as.numeric(data_postscan$Response[data_postscan$norm_fam_qt==1]),na.rm=TRUE)
postscanavg$mean_resp[5*(i-1)+2]=mean(as.numeric(data_postscan$Response[data_postscan$norm_fam_qt==2]),na.rm=TRUE)
postscanavg$mean_resp[5*(i-1)+3]=mean(as.numeric(data_postscan$Response[data_postscan$norm_fam_qt==3]),na.rm=TRUE)
postscanavg$mean_resp[5*(i-1)+4]=mean(as.numeric(data_postscan$Response[data_postscan$norm_fam_qt==4]),na.rm=TRUE)
postscanavg$mean_resp[5*(i-1)+5]=mean(as.numeric(data_postscan$Response[data_postscan$norm_fam_qt==5]),na.rm=TRUE)
#RT average
freqRTavg$SSID[(5*(i-1)+1):(5*i)]=ss_list[i]
freqRTavg$resp[(5*(i-1)+1):(5*i)]=seq(1,5,1)
#each level of obj_freq
freqRTavg$mean_RT[5*(i-1)+1]=mean(as.numeric(data_freq$RespTime[data_freq$Response==1]),na.rm=TRUE)
freqRTavg$mean_RT[5*(i-1)+2]=mean(as.numeric(data_freq$RespTime[data_freq$Response==2]),na.rm=TRUE)
freqRTavg$mean_RT[5*(i-1)+3]=mean(as.numeric(data_freq$RespTime[data_freq$Response==3]),na.rm=TRUE)
freqRTavg$mean_RT[5*(i-1)+4]=mean(as.numeric(data_freq$RespTime[data_freq$Response==4]),na.rm=TRUE)
freqRTavg$mean_RT[5*(i-1)+5]=mean(as.numeric(data_freq$RespTime[data_freq$Response==5]),na.rm=TRUE)
famRTavg$SSID[(5*(i-1)+1):(5*i)]=ss_list[i]
famRTavg$resp[(5*(i-1)+1):(5*i)]=seq(1,5,1)
#each level of obj_freq
famRTavg$mean_RT[5*(i-1)+1]=mean(as.numeric(data_fam$RespTime[data_fam$Response==1]),na.rm=TRUE)
famRTavg$mean_RT[5*(i-1)+2]=mean(as.numeric(data_fam$RespTime[data_fam$Response==2]),na.rm=TRUE)
famRTavg$mean_RT[5*(i-1)+3]=mean(as.numeric(data_fam$RespTime[data_fam$Response==3]),na.rm=TRUE)
famRTavg$mean_RT[5*(i-1)+4]=mean(as.numeric(data_fam$RespTime[data_fam$Response==4]),na.rm=TRUE)
famRTavg$mean_RT[5*(i-1)+5]=mean(as.numeric(data_fam$RespTime[data_fam$Response==5]),na.rm=TRUE)
#correlation
corr_freq=corr.test(as.numeric(data_freq$Response),data_freq$objective_freq,method="pearson")
freq_frame$SSID[i]=ss_list[i]
freq_frame$task[i]="recent"
freq_frame$pearson_R[i]=corr_freq[1]
corr_fam=corr.test(as.numeric(data_fam$Response),data_fam$norm_fam,method="pearson")
fam_frame$SSID[i]=ss_list[i]
fam_frame$task[i]="lifetime"
fam_frame$pearson_R[i]=corr_fam[1]
corr_postscan=corr.test(as.numeric(data_postscan$Response),data_postscan$norm_fam,method="pearson")
postscan_frame$SSID[i]=ss_list[i]
postscan_frame$task[i]="post_scan"
postscan_frame$pearson_R[i]=corr_postscan[1]
}
View(famavg)
fam_frame$pearson_R=as.numeric(fam_frame$pearson_R)
freq_frame$pearson_R=as.numeric(freq_frame$pearson_R)
postscan_frame$pearson_R=as.numeric(postscan_frame$pearson_R)
bsize=0.1
library(ggplot2)
library(dplyr)
freq.sum=freqavg %>%
group_by(obj_freq) %>%
summarise(sub_mean=mean(mean_resp),sub_sd=sd(mean_resp),sub_se=sd(mean_resp)/sqrt(n()))
freq.bar=ggplot(freq.sum,aes(x=obj_freq,y=sub_mean))+geom_col()+geom_errorbar(aes(ymin=sub_mean-sub_se,ymax=sub_mean+sub_se),width=0.2)+theme(axis.text=element_text(size=(15)),axis.title=element_text(size=(15)))+geom_line(data=freqavg,aes(x=obj_freq,y=mean_resp))
freq.bar
View(freq.sum)
freq.bar=ggplot(freq.sum,aes(x=obj_freq,y=sub_mean))+geom_col()+geom_errorbar(aes(ymin=sub_mean-sub_se,ymax=sub_mean+sub_se),width=0.2)+theme(axis.text=element_text(size=(15)),axis.title=element_text(size=(15)))+geom_line(data=freq.sum,aes(x=obj_freq,y=sub_mean))
freq.bar
freq.bar=ggplot(freq.sum,aes(x=obj_freq,y=sub_mean))+geom_col()+geom_errorbar(aes(ymin=sub_mean-sub_se,ymax=sub_mean+sub_se),width=0.2)+theme(axis.text=element_text(size=(15)),axis.title=element_text(size=(15)))+geom_smooth(data=freq.sum,aes(x = obj_freq, y = sub_mean),method = "lm", se= FALSE, color = "firebrick1", size = 2)
freq.bar
freq.bar=ggplot(freq.sum,aes(x=obj_freq,y=sub_mean))+geom_col()+geom_errorbar(aes(ymin=sub_mean-sub_se,ymax=sub_mean+sub_se),width=0.2)+theme(axis.text=element_text(size=(15)),axis.title=element_text(size=(15)))+geom_smooth(data=freq.sum,aes(x = obj_freq, y = sub_mean),method = "lm", se= FALSE, color = "firebrick1", size = 1)
freq.bar
fam.sum=famavg %>%
group_by(norm_fam) %>%
summarise(sub_mean=mean(mean_resp),sub_sd=sd(mean_resp),sub_se=sd(mean_resp)/sqrt(n()))
View(fam.sum)
postscan.sum=postscanavg %>%
group_by(norm_fam) %>%
summarise(sub_mean=mean(mean_resp),sub_sd=sd(mean_resp),sub_se=sd(mean_resp)/sqrt(n()))
View(postscan.sum)
#use piping to chain functions
freq.sum=freqavg %>%
group_by(obj_freq) %>%
summarise(sub_mean=mean(mean_resp),sub_sd=sd(mean_resp),sub_se=sd(mean_resp)/sqrt(n()))
freq.bar=ggplot(freq.sum,aes(x=obj_freq,y=sub_mean))+geom_col()+geom_errorbar(aes(ymin=sub_mean-sub_se,ymax=sub_mean+sub_se),width=0.2)+theme(axis.text=element_text(size=(15)),axis.title=element_text(size=(15)))+geom_smooth(data=freq.sum,aes(x = obj_freq, y = sub_mean),method = "lm", se= FALSE, color = "firebrick1", size = 1)
ggsave(filename='freq_bar.png',path=paste(datapath,'interim_summary\\',sep=''),plot=freq.bar,dpi=300,scale = 0.9)
fam.sum=famavg %>%
group_by(norm_fam) %>%
summarise(sub_mean=mean(mean_resp),sub_sd=sd(mean_resp),sub_se=sd(mean_resp)/sqrt(n()))
fam.bar=ggplot(fam.sum,aes(x=norm_fam,y=sub_mean))+geom_col()+geom_errorbar(aes(ymin=sub_mean-sub_se,ymax=sub_mean+sub_se),width=0.2)+theme(axis.text=element_text(size=(15)),axis.title=element_text(size=(15)))+geom_smooth(data=fam.sum,aes(x = norm_fam, y = sub_mean),method = "lm", se= FALSE, color = "firebrick1", size = 1)
ggsave(filename='fam_bar.png',path=paste(datapath,'interim_summary\\',sep=''),plot=fam.bar,dpi=300,scale = 0.9)
postscan.sum=postscanavg %>%
group_by(norm_fam) %>%
summarise(sub_mean=mean(mean_resp),sub_sd=sd(mean_resp),sub_se=sd(mean_resp)/sqrt(n()))
postscan.bar=ggplot(postscan.sum,aes(x=norm_fam,y=sub_mean))+geom_col()+geom_errorbar(aes(ymin=sub_mean-sub_se,ymax=sub_mean+sub_se),width=0.2)+theme(axis.text=element_text(size=(15)),axis.title=element_text(size=(15)))+geom_smooth(data=postscan.sum,aes(x = norm_fam, y = sub_mean),method = "lm", se= FALSE, color = "firebrick1", size = 1)
ggsave(filename='postscan_bar.png',path=paste(datapath,'interim_summary\\',sep=''),plot=postscan.bar,dpi=300,scale = 0.9)
View(freq_frame)
View(fam_frame)
library(label4MRI)
mni_to_region_name(x=55, y=47,z=113)
mni_to_region_name(x=-38, y=-82,z=40)
i=19
data_dir=paste(datapath,"behavioral\\sub-",ss_list[i],sep="")
data_file=list.files(data_dir,pattern=paste("^",ss_list[i],"_startphase*",sep=""))
data=read_excel(paste(data_dir,"\\",data_file,sep=""))
#remove rows with all NAs but two columns
data=data[rowSums(is.na(data)) != ncol(data)-2, ]
#extract testphase data
data_freq=data[data$task=="recent",]
data_fam=data[data$task=="lifetime",]
data_postscan=data[data$task=="post_scan",]
View(data_fam)
View(data_freq)
