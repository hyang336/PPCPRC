#020 and 022 are below the 2SD cutoff, they also have negative correlations
#replace postscan ratings with norm ratings for 020 and 022
freqpost_frame_corr$pearson_R[freqpost_frame_corr$SSID=='020']=freqnorm_frame$pearson_R[freqnorm_frame$SSID=='020']
freqpost_frame_corr$pearson_R[freqpost_frame_corr$SSID=='022']=freqnorm_frame$pearson_R[freqnorm_frame$SSID=='022']
#t test correlation between freq judgement and postscan ratings against 0
t.test(unlist(freqpost_frame_corr$pearson_R))
#t tests for freq and fam judgement, excluding sub-010
freq_frame=freq_frame[freq_frame$SSID!='010',]
t.test(unlist(freq_frame$pearson_R))
fam_frame=fam_frame[fam_frame$SSID!='010',]
t.test(unlist(fam_frame$pearson_R))
postscan_frame=postscan_frame[postscan_frame$SSID!='010',]
t.test(unlist(postscan_frame$pearson_R))
#t test for correlation between postscan and objective frequency
objfreqpostscan_frame_corr=objfreqpostscan_frame[objfreqpostscan_frame$SSID!='010',]#remove sub-010
#replace postscan ratings with norm ratings for 020 and 022
objfreqpostscan_frame_corr$pearson_R[objfreqpostscan_frame_corr$SSID=='020']=normobjfreq_frame$pearson_R[normobjfreq_frame$SSID=='020']
objfreqpostscan_frame_corr$pearson_R[objfreqpostscan_frame_corr$SSID=='022']=normobjfreq_frame$pearson_R[normobjfreq_frame$SSID=='022']
t.test(unlist(objfreqpostscan_frame_corr$pearson_R))
#RT analyses of the frequency task, also as a basis to define accurate and inaccurate trials for DDM
#create objective freq rank
data_freq_all$objective_freq_rank[data_freq_all$objective_freq==9]=5
data_freq_all$objective_freq_rank[data_freq_all$objective_freq==7]=4
data_freq_all$objective_freq_rank[data_freq_all$objective_freq==5]=3
data_freq_all$objective_freq_rank[data_freq_all$objective_freq==3]=2
data_freq_all$objective_freq_rank[data_freq_all$objective_freq==1]=1
#if the objective freq rank and participants responses differ more than 1, a trial is marked as inaccurate
data_freq_all$accuracy=0
data_freq_all$accuracy[abs(as.numeric(data_freq_all$Response)-data_freq_all$objective_freq_rank)<=1]=1#1 means correct
#average RT across accurate and inaccurate trials separately for each subject
library(dplyr)
data_freq_summary=data_freq_all %>%
group_by(ParticipantNum,accuracy) %>%
summarise(mean = mean(RespTime,na.rm=TRUE), n = n())
#paired t-test
t.test(data_freq_summary$mean[data_freq_summary$accuracy==0],data_freq_summary$mean[data_freq_summary$accuracy==1],paired=TRUE,alternative='greater')
#only significant in one-tailed test, possibly due to our definition of accuracy being a bit lenient
#This is what Stefan suggested, comparing RT for trials rated as 5 while having only 1 or 3 presentations vs. those having 7 or 9 presentations during the study
data_freq_only5=data_freq_all[as.numeric(data_freq_all$Response)==5&!is.na(data_freq_all$Response),]
data_freq_only5=data_freq_only5[data_freq_only5$objective_freq_rank!=3,]
data_freq_only5$obj_freq_bin[data_freq_only5$objective_freq_rank==4|data_freq_only5$objective_freq_rank==5]=1
data_freq_only5$obj_freq_bin[data_freq_only5$objective_freq_rank==1|data_freq_only5$objective_freq_rank==2]=0
data_freq_only5_summary=data_freq_only5 %>%
group_by(ParticipantNum,obj_freq_bin) %>%
summarise(mean = mean(RespTime,na.rm=TRUE), n = n())#some subjects have no lower bin
#get rid of people with only one bin
sub_bin_count=count(data_freq_only5_summary,var='ParticipantNum')
droplist=sub_bin_count$ParticipantNum[sub_bin_count$n==1]
data_freq_only5_summary.complete=data_freq_only5_summary[!is.element(data_freq_only5_summary$ParticipantNum,droplist),]
#stats
t.test(data_freq_only5_summary.complete$mean[data_freq_only5_summary.complete$obj_freq_bin==1],data_freq_only5_summary.complete$mean[data_freq_only5_summary.complete$obj_freq_bin==0],paired=TRUE)
#not significant, but these are based on a very small number of trials
library(dplyr)
freq.sum=freqavg %>%
group_by(obj_freq) %>%
summarise(sub_mean=mean(mean_resp),sub_sd=sd(mean_resp),sub_se=sd(mean_resp)/sqrt(n()))
freq.bar=ggplot(freq.sum,aes(x=obj_freq,y=sub_mean))+geom_col()+geom_errorbar(aes(ymin=sub_mean-sub_se,ymax=sub_mean+sub_se),width=0.2)+theme(axis.text=element_text(size=(15)),axis.title=element_text(size=(15)))+geom_smooth(data=freq.sum,aes(x = obj_freq, y = sub_mean),method = "lm", se= FALSE, color = "firebrick1", size = 1)
bsize=0.1
library(ggplot2)
freq.sum=freqavg %>%
group_by(obj_freq) %>%
summarise(sub_mean=mean(mean_resp),sub_sd=sd(mean_resp),sub_se=sd(mean_resp)/sqrt(n()))
freq.bar=ggplot(freq.sum,aes(x=obj_freq,y=sub_mean))+geom_col()+geom_errorbar(aes(ymin=sub_mean-sub_se,ymax=sub_mean+sub_se),width=0.2)+theme(axis.text=element_text(size=(15)),axis.title=element_text(size=(15)))+geom_smooth(data=freq.sum,aes(x = obj_freq, y = sub_mean),method = "lm", se= FALSE, color = "firebrick1", size = 1)
freq.bar
freq.bar=ggplot(freq.sum,aes(x=obj_freq,y=sub_mean))+
geom_col()+geom_errorbar(aes(ymin=sub_mean-sub_se,ymax=sub_mean+sub_se),width=0.2)+
theme(axis.text=element_text(size=(15)),axis.title=element_text(size=(15)))+
geom_smooth(data=freq.sum,aes(x = obj_freq, y = sub_mean),method = "lm", se= FALSE, color = "firebrick1", size = 1)+
xlab("objective presentation frequency")+
ylab("subjective rating")+
scale_x_discrete(labels=c(1,3,5,7,9))
freq.bar
freq.bar=ggplot(freq.sum,aes(x=obj_freq,y=sub_mean))+
geom_col()+geom_errorbar(aes(ymin=sub_mean-sub_se,ymax=sub_mean+sub_se),width=0.2)+
theme(axis.text=element_text(size=(15)),axis.title=element_text(size=(15)))+
geom_smooth(data=freq.sum,aes(x = obj_freq, y = sub_mean),method = "lm", se= FALSE, color = "firebrick1", size = 1)+
xlab("objective presentation frequency")+
ylab("subjective rating")+
scale_x_discrete("obj_freq",labels=c(1,3,5,7,9))
freq.bar
View(freq.sum)
freq.bar=ggplot(freq.sum,aes(x=obj_freq,y=sub_mean))+
geom_col()+geom_errorbar(aes(ymin=sub_mean-sub_se,ymax=sub_mean+sub_se),width=0.2)+
theme(axis.text=element_text(size=(15)),axis.title=element_text(size=(15)))+
geom_smooth(data=freq.sum,aes(x = obj_freq, y = sub_mean),method = "lm", se= FALSE, color = "firebrick1", size = 1)+
xlab("objective presentation frequency")+
ylab("subjective rating")+
scale_x_discrete("obj_freq",breaks=c(1,3,5,7,9),labels=c(1,3,5,7,9))
View(freq.sum)
freq.bar
freq.bar=ggplot(freq.sum,aes(x=obj_freq,y=sub_mean))+
geom_col()+geom_errorbar(aes(ymin=sub_mean-sub_se,ymax=sub_mean+sub_se),width=0.2)+
theme(axis.text=element_text(size=(15)),axis.title=element_text(size=(15)))+
geom_smooth(data=freq.sum,aes(x = obj_freq, y = sub_mean),method = "lm", se= FALSE, color = "firebrick1", size = 1)+
xlab("objective presentation frequency")+
ylab("subjective rating")+
scale_x_continuous(breaks=c(1,3,5,7,9))
freq.bar
ggsave(filename='freq_bar.png',path=paste(datapath,'interim_summary\\ch2_figs\\',sep=''),plot=freq.bar,width=4,height=4,units="in",dpi=300,scale = 0.9)
View(fam.sum)
fam.sum=famavg %>%
group_by(norm_fam) %>%
summarise(sub_mean=mean(mean_resp),sub_sd=sd(mean_resp),sub_se=sd(mean_resp)/sqrt(n()))
fam.bar=ggplot(fam.sum,aes(x=norm_fam,y=sub_mean))+
geom_col()+geom_errorbar(aes(ymin=sub_mean-sub_se,ymax=sub_mean+sub_se),width=0.2)+
theme(axis.text=element_text(size=(15)),axis.title=element_text(size=(15)))+
geom_smooth(data=fam.sum,aes(x = norm_fam, y = sub_mean),method = "lm", se= FALSE, color = "firebrick1", size = 1)+
xlab("normative lifetime familiarity")+
ylab("subjective rating")+
scale_x_continuous(breaks=c(1,2,3,4,5))
ggsave(filename='fam_bar.png',path=paste(datapath,'interim_summary\\ch2_figs\\',sep=''),plot=fam.bar,width=4,height=4,units="in",dpi=300,scale = 0.9)
postscan.sum=postscanavg %>%
group_by(norm_fam) %>%
summarise(sub_mean=mean(mean_resp),sub_sd=sd(mean_resp),sub_se=sd(mean_resp)/sqrt(n()))
postscan.bar=ggplot(postscan.sum,aes(x=norm_fam,y=sub_mean))+
geom_col()+geom_errorbar(aes(ymin=sub_mean-sub_se,ymax=sub_mean+sub_se),width=0.2)+
theme(axis.text=element_text(size=(15)),axis.title=element_text(size=(15)))+
geom_smooth(data=postscan.sum,aes(x = norm_fam, y = sub_mean),method = "lm", se= FALSE, color = "firebrick1", size = 1)+
xlab("normative lifetime familiarity")+
ylab("subjective rating")+
scale_x_continuous(breaks=c(1,2,3,4,5))
ggsave(filename='postscan_bar.png',path=paste(datapath,'interim_summary\\ch2_figs\\',sep=''),plot=postscan.bar,width=4,height=4,units="in",dpi=300,scale = 0.9)
#check RT priming effect of repetition and lifetime familiarity
library(rio)
datapath="C:\\Users\\haozi\\Desktop\\PhD\\fMRI_PrC-PPC_data\\"
ss_list=c('001','002','003','004','005','006','007','008','011','012','013','014','015','016','017','018','019','020','021','022','023','024','095','026','027','028','029','030','031','032')
#dataframe for saving regression slopes
beta_frame=data.frame(matrix(ncol = 3, nrow = length(ss_list)))
x <- c("SSID","freq_slope","lifetime_slope")
colnames(beta_frame) <- x
RT_freq_frame=data.frame(matrix(ncol = 3,nrow=0))
x <- c("SSID","freq_RT","pres")
colnames(RT_freq_frame) <- x
RT_life_frame=data.frame(matrix(ncol = 3, nrow = 0))
x <- c("SSID","life_RT","lifetime_ratings")
colnames(RT_life_frame) <- x
for (i in c(1:length(ss_list))){
beta_frame$SSID[i]=ss_list[i]
data=import(paste(datapath,'behavioral\\sub-',ss_list[i],'\\',ss_list[i],'_startphase-study_startrun-1_starttrial-1_data.xlsx',sep=''))
animacy_data=data[data$task=='animacy',]
postscan_data=data[data$task=='post_scan',]
animacy_data=animacy_data[rowSums(is.na(animacy_data)) != ncol(animacy_data), ]#remove all-NA rows
postscan_data=postscan_data[rowSums(is.na(postscan_data)) != ncol(postscan_data), ]#remove all-NA rows
#load postscan data into the animacy data
for (j in c(1:dim(animacy_data)[1])){
animacy_data$postscan[j]=postscan_data$Response[postscan_data$Stimuli==animacy_data$Stimuli[j]]
}
#extract mean RT for each level of repetition and lifetime familiarity for plots
RT.pres1=mean(animacy_data$RespTime[animacy_data$objective_freq%%10==1],na.rm=TRUE)
RT.pres2=mean(animacy_data$RespTime[animacy_data$objective_freq%%10==2],na.rm=TRUE)
RT.pres3=mean(animacy_data$RespTime[animacy_data$objective_freq%%10==3],na.rm=TRUE)
RT.pres4=mean(animacy_data$RespTime[animacy_data$objective_freq%%10==4],na.rm=TRUE)
RT.pres5=mean(animacy_data$RespTime[animacy_data$objective_freq%%10==5],na.rm=TRUE)
RT.pres6=mean(animacy_data$RespTime[animacy_data$objective_freq%%10==6],na.rm=TRUE)
RT.pres7=mean(animacy_data$RespTime[animacy_data$objective_freq%%10==7],na.rm=TRUE)
RT.pres8=mean(animacy_data$RespTime[animacy_data$objective_freq%%10==8],na.rm=TRUE)
RT.pres9=mean(animacy_data$RespTime[animacy_data$objective_freq%%10==9],na.rm=TRUE)
RT.freq_temp=cbind(rep(ss_list[i],9),rbind(RT.pres1,RT.pres2,RT.pres3,RT.pres4,RT.pres5,RT.pres6,RT.pres7,RT.pres8,RT.pres9),seq(1,9))
x <- c("SSID","freq_RT","pres")
colnames(RT.freq_temp) <- x
RT_freq_frame=rbind(RT_freq_frame,RT.freq_temp)
RT.life1=mean(animacy_data$RespTime[animacy_data$postscan==1],na.rm = TRUE)
RT.life2=mean(animacy_data$RespTime[animacy_data$postscan==2],na.rm = TRUE)
RT.life3=mean(animacy_data$RespTime[animacy_data$postscan==3],na.rm = TRUE)
RT.life4=mean(animacy_data$RespTime[animacy_data$postscan==4],na.rm = TRUE)
RT.life5=mean(animacy_data$RespTime[animacy_data$postscan==5],na.rm = TRUE)
RT.life_temp=cbind(rep(ss_list[i],5),rbind(RT.life1,RT.life2,RT.life3,RT.life4,RT.life5),seq(1,5))
x <- c("SSID","life_RT","lifetime_ratings")
colnames(RT.life_temp) <- x
RT_life_frame=rbind(RT_life_frame,RT.life_temp)
#z-score all continuous or ordinal variables (RT, freq, norm_fam, postscan fam)
animacy_data$RT_z=scale(animacy_data$RespTime)
animacy_data$freq_z=scale(animacy_data$objective_freq%%10)
animacy_data$norm_fam_z=scale(animacy_data$norm_fam)
animacy_data$postscan_z=scale(as.numeric(animacy_data$postscan))
#replacing normfam with postscan fam is participant rating exists (except for sub-020 and sub-022 since they have abnormal post-scan lifetime ratings)
animacy_data$lifetime_z=animacy_data$norm_fam_z
if (ss_list[i]!='020'&&ss_list[i]!='022'){
for (k in c(1:dim(animacy_data)[1])){
if (!is.na(animacy_data$postscan_z[k])){
animacy_data$lifetime_z[k]=animacy_data$postscan_z[k]
}
}
}
#run regression RT~freq+fam in animacy task
RT_reg=lm(RT_z~freq_z+lifetime_z,data=animacy_data)#regress RT and
#extract coefficients for 2nd level tests
beta_frame$freq_slope[i]=RT_reg$coefficients[[2]]
beta_frame$lifetime_slope[i]=RT_reg$coefficients[[3]]
}
#t tests for regression slope of freq & life on RT against 0
t.test(beta_frame$freq_slope)#highly significant
t.test(beta_frame$lifetime_slope)#still significant
#priming effect (i.e. reduction in RT) was observed for both factors
#plot RT across repetitions
library(ggplot2)
#summary stats
RT.freq_sum=data.frame(matrix(ncol = 3,nrow=0))
x <- c("pres","rt","se")
colnames(RT.freq_sum) <- x
for (i in seq(1,9)){
RT.freq_sum=rbind(RT.freq_sum,data.frame(pres=i,rt=mean(as.numeric(RT_freq_frame$freq_RT[RT_freq_frame$pres==i]),na.rm=TRUE),se=sd(RT_freq_frame$freq_RT[RT_freq_frame$pres==i],na.rm=TRUE)/sqrt(length(RT_freq_frame$freq_RT[RT_freq_frame$pres==i&!is.na(RT_freq_frame$freq_RT)]))))
}
RT.life_sum=data.frame(matrix(ncol = 3,nrow=0))
x <- c("lifetime_ratings","rt","se")
colnames(RT.life_sum) <- x
for (i in seq(1,5)){
RT.life_sum=rbind(RT.life_sum,data.frame(lifetime_ratings=i,rt=mean(as.numeric(RT_life_frame$life_RT[RT_life_frame$lifetime_ratings==i]),na.rm=TRUE),se=sd(RT_life_frame$life_RT[RT_life_frame$lifetime_ratings==i],na.rm=TRUE)/sqrt(length(RT_life_frame$life_RT[RT_life_frame$lifetime_ratings==i&!is.na(RT_life_frame$life_RT)]))))
}
#freq RT plot
p1=ggplot(data = RT.freq_sum,aes(x=as.factor(pres),y = rt,group=1)) +
geom_line()+
geom_point()+
geom_errorbar(aes(ymin=rt-se, ymax=rt+se), width=.2,position=position_dodge(.9))
#lifetime RT plot
p2=ggplot(data = RT.life_sum,aes(x=as.factor(lifetime_ratings),y = rt,group=1)) +
geom_line()+
geom_point()+
geom_errorbar(aes(ymin=rt-se, ymax=rt+se), width=.2,position=position_dodge(.9))
p1
p2
p1
p1=ggplot(data = RT.freq_sum,aes(x=as.factor(pres),y = rt,group=1)) +
geom_col()+
geom_point()+
geom_errorbar(aes(ymin=rt-se, ymax=rt+se), width=.2,position=position_dodge(.9))
p1
p1=ggplot(data = RT.freq_sum,aes(x=as.factor(pres),y = rt,group=1)) +
geom_line()+
geom_point()+
geom_errorbar(aes(ymin=rt-se, ymax=rt+se), width=.2,position=position_dodge(.9))
p1
p1=ggplot(data = RT.freq_sum,aes(x=as.factor(pres),y = rt,group=1)) +
geom_line()+
geom_point()+
theme(axis.text=element_text(size=(15)),axis.title=element_text(size=(15)))+
geom_errorbar(aes(ymin=rt-se, ymax=rt+se), width=.2,position=position_dodge(.9))+
xlab("objective presentation frequency")+
ylab("response time (second)")
p1
p2=ggplot(data = RT.life_sum,aes(x=as.factor(lifetime_ratings),y = rt,group=1)) +
geom_line()+
geom_point()+
theme(axis.text=element_text(size=(15)),axis.title=element_text(size=(15)))+
geom_errorbar(aes(ymin=rt-se, ymax=rt+se), width=.2,position=position_dodge(.9))+
xlab("normative lifetime familiarity")+
ylab("response time (second)")
p2
ggsave(filename='study_freq_RT.png',path=paste(datapath,'interim_summary\\ch2_figs\\',sep=''),plot=p1,width=4,height=4,units="in",dpi=300,scale = 0.9)
ggsave(filename='study_fam_RT.png',path=paste(datapath,'interim_summary\\ch2_figs\\',sep=''),plot=p2,width=4,height=4,units="in",dpi=300,scale = 0.9)
ggsave(filename='study_freq_RT.png',path=paste(datapath,'interim_summary\\ch2_figs\\',sep=''),plot=p1,width=4,height=4,units="in",dpi=300,scale = 1)
ggsave(filename='study_fam_RT.png',path=paste(datapath,'interim_summary\\ch2_figs\\',sep=''),plot=p2,width=4,height=4,units="in",dpi=300,scale = 1)
datapath="C:\\Users\\haozi\\Desktop\\PhD\\fMRI_PrC-PPC_data\\"
library(psych)
library(readxl)
library(scales)
ss_list=c('001','002','003','004','005','006','007','008','011','012','013','014','015','016','017','018','019','020','021','022','023','024','095','026','027','028','029','030','031','032')
freq_error.on.pscan=data.frame(matrix(ncol=2,nrow=length(ss_list)))
x=c("slope","SSID")
colnames(freq_error.on.pscan)=x
for (i in c(1:length(ss_list))){
#load behavioral results
data_dir=paste(datapath,"behavioral\\sub-",ss_list[i],sep="")
data_file=list.files(data_dir,pattern=paste("^",ss_list[i],"_startphase*",sep=""))
data=read_excel(paste(data_dir,"\\",data_file,sep=""))
#remove rows with all NAs but two columns
data=data[rowSums(is.na(data)) != ncol(data)-2, ]
#extract testphase data
data_freq=data[data$task=="recent",]
data_fam=data[data$task=="lifetime",]
data_postscan=data[data$task=="post_scan",]
#match item order of freq with postscan
data_freq.match=data_freq[match(data_postscan$Stimuli,data_freq$Stimuli),]#match item order
data_freq.match$postscan=data_postscan$Response
#rescale obj. freq to 1-5
data_freq.match$objective_freq_rescale=rescale(data_freq.match$objective_freq, to = c(1,5))
#the difference between judged freq and obj. freq should scale with lifetime familiarity, for now we use subject-specific lifetime ratings
freq_error=as.numeric(data_freq.match$Response)-data_freq.match$objective_freq_rescale
m1=lm(freq_error~as.numeric(data_freq.match$postscan))
freq_error.on.pscan$slope[i]=m1[[1]][[2]]
freq_error.on.pscan$SSID[i]=ss_list[i]
}
View(freq_error.on.pscan)
View(data_freq.match)
freq_error_pscan=data.frame(matrix(ncol = 6, nrow = length(ss_list)))
x <- c("SSID","freq_err_ps1","freq_err_ps2","freq_err_ps3","freq_err_ps4","freq_err_ps5")
colnames(freq_error_pscan) <- x
freq_error_pscan
freq_error[data_freq.match$postscan==1]
datapath="C:\\Users\\haozi\\Desktop\\PhD\\fMRI_PrC-PPC_data\\"
library(psych)
library(readxl)
library(scales)
ss_list=c('001','002','003','004','005','006','007','008','011','012','013','014','015','016','017','018','019','020','021','022','023','024','095','026','027','028','029','030','031','032')
freq_error.on.pscan=data.frame(matrix(ncol=2,nrow=length(ss_list)))
x=c("slope","SSID")
colnames(freq_error.on.pscan)=x
freq_error_pscan=data.frame(matrix(ncol = 6, nrow = length(ss_list)))
x <- c("SSID","freq_err_ps1","freq_err_ps2","freq_err_ps3","freq_err_ps4","freq_err_ps5")
colnames(freq_error_pscan) <- x
for (i in c(1:length(ss_list))){
#load behavioral results
data_dir=paste(datapath,"behavioral\\sub-",ss_list[i],sep="")
data_file=list.files(data_dir,pattern=paste("^",ss_list[i],"_startphase*",sep=""))
data=read_excel(paste(data_dir,"\\",data_file,sep=""))
#remove rows with all NAs but two columns
data=data[rowSums(is.na(data)) != ncol(data)-2, ]
#extract testphase data
data_freq=data[data$task=="recent",]
data_fam=data[data$task=="lifetime",]
data_postscan=data[data$task=="post_scan",]
#match item order of freq with postscan
data_freq.match=data_freq[match(data_postscan$Stimuli,data_freq$Stimuli),]#match item order
data_freq.match$postscan=data_postscan$Response
#rescale obj. freq to 1-5
data_freq.match$objective_freq_rescale=rescale(data_freq.match$objective_freq, to = c(1,5))
#the difference between judged freq and obj. freq should scale with lifetime familiarity, for now we use subject-specific lifetime ratings
freq_error=as.numeric(data_freq.match$Response)-data_freq.match$objective_freq_rescale
#record participant level summary stats for plotting
freq_error_pscan$SSID[ss_list[i]]
freq_error_pscan$freq_err_ps1[i]=mean(freq_error[data_freq.match$postscan==1])
freq_error_pscan$freq_err_ps2[i]=mean(freq_error[data_freq.match$postscan==2])
freq_error_pscan$freq_err_ps3[i]=mean(freq_error[data_freq.match$postscan==3])
freq_error_pscan$freq_err_ps4[i]=mean(freq_error[data_freq.match$postscan==4])
freq_error_pscan$freq_err_ps1[5]=mean(freq_error[data_freq.match$postscan==5])
#regression
m1=lm(freq_error~as.numeric(data_freq.match$postscan))
freq_error.on.pscan$slope[i]=m1[[1]][[2]]
freq_error.on.pscan$SSID[i]=ss_list[i]
}
freq_error_pscan
datapath="C:\\Users\\haozi\\Desktop\\PhD\\fMRI_PrC-PPC_data\\"
library(psych)
library(readxl)
library(scales)
ss_list=c('001','002','003','004','005','006','007','008','011','012','013','014','015','016','017','018','019','020','021','022','023','024','095','026','027','028','029','030','031','032')
freq_error.on.pscan=data.frame(matrix(ncol=2,nrow=length(ss_list)))
x=c("slope","SSID")
colnames(freq_error.on.pscan)=x
freq_error_pscan=data.frame(matrix(ncol = 6, nrow = length(ss_list)))
x <- c("SSID","freq_err_ps1","freq_err_ps2","freq_err_ps3","freq_err_ps4","freq_err_ps5")
colnames(freq_error_pscan) <- x
for (i in c(1:length(ss_list))){
#load behavioral results
data_dir=paste(datapath,"behavioral\\sub-",ss_list[i],sep="")
data_file=list.files(data_dir,pattern=paste("^",ss_list[i],"_startphase*",sep=""))
data=read_excel(paste(data_dir,"\\",data_file,sep=""))
#remove rows with all NAs but two columns
data=data[rowSums(is.na(data)) != ncol(data)-2, ]
#extract testphase data
data_freq=data[data$task=="recent",]
data_fam=data[data$task=="lifetime",]
data_postscan=data[data$task=="post_scan",]
#match item order of freq with postscan
data_freq.match=data_freq[match(data_postscan$Stimuli,data_freq$Stimuli),]#match item order
data_freq.match$postscan=data_postscan$Response
#rescale obj. freq to 1-5
data_freq.match$objective_freq_rescale=rescale(data_freq.match$objective_freq, to = c(1,5))
#the difference between judged freq and obj. freq should scale with lifetime familiarity, for now we use subject-specific lifetime ratings
freq_error=as.numeric(data_freq.match$Response)-data_freq.match$objective_freq_rescale
#record participant level summary stats for plotting
freq_error_pscan$SSID[ss_list[i]]
freq_error_pscan$freq_err_ps1[i]=mean(freq_error[data_freq.match$postscan==1],na.rm=TRUE)
freq_error_pscan$freq_err_ps2[i]=mean(freq_error[data_freq.match$postscan==2],na.rm=TRUE)
freq_error_pscan$freq_err_ps3[i]=mean(freq_error[data_freq.match$postscan==3],na.rm=TRUE)
freq_error_pscan$freq_err_ps4[i]=mean(freq_error[data_freq.match$postscan==4],na.rm=TRUE)
freq_error_pscan$freq_err_ps1[5]=mean(freq_error[data_freq.match$postscan==5],na.rm=TRUE)
#regression
m1=lm(freq_error~as.numeric(data_freq.match$postscan))
freq_error.on.pscan$slope[i]=m1[[1]][[2]]
freq_error.on.pscan$SSID[i]=ss_list[i]
}
freq_error_pscan
View(data_freq.match)
datapath="C:\\Users\\haozi\\Desktop\\PhD\\fMRI_PrC-PPC_data\\"
library(psych)
library(readxl)
library(scales)
ss_list=c('001','002','003','004','005','006','007','008','011','012','013','014','015','016','017','018','019','020','021','022','023','024','095','026','027','028','029','030','031','032')
freq_error.on.pscan=data.frame(matrix(ncol=2,nrow=length(ss_list)))
x=c("slope","SSID")
colnames(freq_error.on.pscan)=x
freq_error_pscan=data.frame(matrix(ncol = 6, nrow = length(ss_list)))
x <- c("SSID","freq_err_ps1","freq_err_ps2","freq_err_ps3","freq_err_ps4","freq_err_ps5")
colnames(freq_error_pscan) <- x
for (i in c(1:length(ss_list))){
#load behavioral results
data_dir=paste(datapath,"behavioral\\sub-",ss_list[i],sep="")
data_file=list.files(data_dir,pattern=paste("^",ss_list[i],"_startphase*",sep=""))
data=read_excel(paste(data_dir,"\\",data_file,sep=""))
#remove rows with all NAs but two columns
data=data[rowSums(is.na(data)) != ncol(data)-2, ]
#extract testphase data
data_freq=data[data$task=="recent",]
data_fam=data[data$task=="lifetime",]
data_postscan=data[data$task=="post_scan",]
#match item order of freq with postscan
data_freq.match=data_freq[match(data_postscan$Stimuli,data_freq$Stimuli),]#match item order
data_freq.match$postscan=data_postscan$Response
#rescale obj. freq to 1-5
data_freq.match$objective_freq_rescale=rescale(data_freq.match$objective_freq, to = c(1,5))
#the difference between judged freq and obj. freq should scale with lifetime familiarity, for now we use subject-specific lifetime ratings
freq_error=as.numeric(data_freq.match$Response)-data_freq.match$objective_freq_rescale
#record participant level summary stats for plotting
freq_error_pscan$SSID[ss_list[i]]
freq_error_pscan$freq_err_ps1[i]=mean(freq_error[data_freq.match$postscan==1],na.rm=TRUE)
freq_error_pscan$freq_err_ps2[i]=mean(freq_error[data_freq.match$postscan==2],na.rm=TRUE)
freq_error_pscan$freq_err_ps3[i]=mean(freq_error[data_freq.match$postscan==3],na.rm=TRUE)
freq_error_pscan$freq_err_ps4[i]=mean(freq_error[data_freq.match$postscan==4],na.rm=TRUE)
freq_error_pscan$freq_err_ps1[i]=mean(freq_error[data_freq.match$postscan==5],na.rm=TRUE)
#regression
m1=lm(freq_error~as.numeric(data_freq.match$postscan))
freq_error.on.pscan$slope[i]=m1[[1]][[2]]
freq_error.on.pscan$SSID[i]=ss_list[i]
}
freq_error_pscan
datapath="C:\\Users\\haozi\\Desktop\\PhD\\fMRI_PrC-PPC_data\\"
library(psych)
library(readxl)
library(scales)
ss_list=c('001','002','003','004','005','006','007','008','011','012','013','014','015','016','017','018','019','020','021','022','023','024','095','026','027','028','029','030','031','032')
freq_error.on.pscan=data.frame(matrix(ncol=2,nrow=length(ss_list)))
x=c("slope","SSID")
colnames(freq_error.on.pscan)=x
freq_error_pscan=data.frame(matrix(ncol = 6, nrow = length(ss_list)))
x <- c("SSID","freq_err_ps1","freq_err_ps2","freq_err_ps3","freq_err_ps4","freq_err_ps5")
colnames(freq_error_pscan) <- x
for (i in c(1:length(ss_list))){
#load behavioral results
data_dir=paste(datapath,"behavioral\\sub-",ss_list[i],sep="")
data_file=list.files(data_dir,pattern=paste("^",ss_list[i],"_startphase*",sep=""))
data=read_excel(paste(data_dir,"\\",data_file,sep=""))
#remove rows with all NAs but two columns
data=data[rowSums(is.na(data)) != ncol(data)-2, ]
#extract testphase data
data_freq=data[data$task=="recent",]
data_fam=data[data$task=="lifetime",]
data_postscan=data[data$task=="post_scan",]
#match item order of freq with postscan
data_freq.match=data_freq[match(data_postscan$Stimuli,data_freq$Stimuli),]#match item order
data_freq.match$postscan=data_postscan$Response
#rescale obj. freq to 1-5
data_freq.match$objective_freq_rescale=rescale(data_freq.match$objective_freq, to = c(1,5))
#the difference between judged freq and obj. freq should scale with lifetime familiarity, for now we use subject-specific lifetime ratings
freq_error=as.numeric(data_freq.match$Response)-data_freq.match$objective_freq_rescale
#record participant level summary stats for plotting
freq_error_pscan$SSID[i]=ss_list[i]
freq_error_pscan$freq_err_ps1[i]=mean(freq_error[data_freq.match$postscan==1],na.rm=TRUE)
freq_error_pscan$freq_err_ps2[i]=mean(freq_error[data_freq.match$postscan==2],na.rm=TRUE)
freq_error_pscan$freq_err_ps3[i]=mean(freq_error[data_freq.match$postscan==3],na.rm=TRUE)
freq_error_pscan$freq_err_ps4[i]=mean(freq_error[data_freq.match$postscan==4],na.rm=TRUE)
freq_error_pscan$freq_err_ps5[i]=mean(freq_error[data_freq.match$postscan==5],na.rm=TRUE)
#regression
m1=lm(freq_error~as.numeric(data_freq.match$postscan))
freq_error.on.pscan$slope[i]=m1[[1]][[2]]
freq_error.on.pscan$SSID[i]=ss_list[i]
}
freq_error_pscan
results_col=colnames(freq_error_pscan)
results_col
str(results_col)
results_col=colnames(freq_error_pscan)[2:]
results_col=results_col[!results_col&in% 1]
results_col=results_col[!results_col%in% 1]
results_col
results_col=results_col[!results_col%in% c(1)]
results_col
results_col=results_col[results_col%in% 2:]
results_col=results_col[results_col%in% 2::]
results_col=results_col[results_col%in% 2:end]
results_col=results_col[-1]
results_col
for (i in seq(1,5)){
coln=results_col[i]
mirror_sum=rbind(mirror_sum,data.frame(pscan=i,freq_error=mean(as.numeric(freq_error_pscan[,coln]),na.rm=TRUE),se=sd(freq_error_pscan[,coln],na.rm=TRUE)/sqrt(length(freq_error_pscan[,coln]))))
}
mirror_sum=data.frame(matrix(ncol = 3,nrow=0))
x <- c("pscan","freq_error","se")
colnames(mirror_sum) <- x
for (i in seq(1,5)){
coln=results_col[i]
mirror_sum=rbind(mirror_sum,data.frame(pscan=i,freq_error=mean(as.numeric(freq_error_pscan[,coln]),na.rm=TRUE),se=sd(freq_error_pscan[,coln],na.rm=TRUE)/sqrt(length(freq_error_pscan[,coln]))))
}
mirror_sum
####For plot##############
libaray(ggplot2)
####For plot##############
library(ggplot2)
freq_err.bar=ggplot(mirror_sum,aes(x=pscan,y=freq_error))+
geom_col()+geom_errorbar(aes(ymin=freq_error-se,ymax=freq_error+se),width=0.2)+
theme(axis.text.y=element_text(size=(15)),axis.text.x = element_text(size=13))+
xlab("post-scan lifetime familiarity ratings")+
ylab("Frequency overestimation")
freq_err.bar
freq_err.bar=ggplot(mirror_sum,aes(x=pscan,y=freq_error))+
geom_col()+geom_errorbar(aes(ymin=freq_error-se,ymax=freq_error+se),width=0.2)+
theme(axis.text.y=element_text(size=15),axis.text.x = element_text(size=13))+
xlab("post-scan lifetime familiarity ratings")+
ylab("Frequency overestimation")
freq_err.bar
freq_err.bar=ggplot(mirror_sum,aes(x=pscan,y=freq_error))+
geom_col()+geom_errorbar(aes(ymin=freq_error-se,ymax=freq_error+se),width=0.2)+
theme(axis.text=element_text(size=15),axis.title.x = element_text(size=13),axis.title.y = element_text(size=15))+
xlab("post-scan lifetime familiarity ratings")+
ylab("Frequency overestimation")
freq_err.bar
freq_err.bar=ggplot(mirror_sum,aes(x=pscan,y=freq_error))+
geom_col()+geom_errorbar(aes(ymin=freq_error-se,ymax=freq_error+se),width=0.2)+
theme(axis.text=element_text(size=15),axis.title.x = element_text(size=13),axis.title.y = element_text(size=15))+
xlab("post-scan lifetime familiarity ratings")+
ylab("frequency overestimation")
ggsave(filename='freqerror_bar.png',path=paste(datapath,'interim_summary\\ch2_figs\\',sep=''),plot=freq_err.bar,width=4,height=4,units="in",dpi=300,scale = 1)
